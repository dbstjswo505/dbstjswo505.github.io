---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# üòÉ About me

I graduated from the Daegu Gyeongbuk Institute of Science & Technology (DGIST) with a B.S. in Computer Engineering in 2019 and from Korea Advanced Institute of Science& Technology (KAIST) with a M.S. in Electric Engineering in 2021. I decided to continue my education and pursue a Ph.D. in the field of Artificial Intelligence/Deep Learning. I am currently working under the guidance of Professor [Chang D. Yoo](http://sanctusfactory.com/family.php), whose expertise and leadership have been invaluable to my research.

My research focuses on the reliability of Artificial Intelligence/Deep Learning technologies for various modalities, including images, videos, and natural language. I am passionate about exploring the potential of these technologies and finding ways to improve their performance and reliability in real-world applications.

# üéè Research Interests
- Computer Vision
- Natural Language Processing
- Multi-modal Reasoning
- Causality and Debiasing
- Generative AI


# üî• News
- *2023.11*: &nbsp;üèÜ I got [Best Paper Award](https://ee.kaist.ac.kr/en/research-achieve/ph-d-candidate-sunjae-yoon-prof-chang-d-yoo-wins-best-paper-award/) in JKAIA 2023 
- *2023.10*: &nbsp;üéâ One paper accepted to ICCV 2023 

# üè´ Education

- Mar.2021 - Current: __Ph.D candidate__ Electrical Engineering (KAIST)

&emsp;&emsp;&emsp;Advisor: Prof. Chang D. Yoo

- Sep.2019 - Feb.2021: __M.S.__ Electrical Engineering (KAIST)

&emsp;&emsp;&emsp;Thesis: "Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval"

&emsp;&emsp;&emsp;Advisor: Prof. Chang D. Yoo

- Mar.2015 - Feb.2019: __B.S.__ Computer Engineering (DGIST)

# üí¨ Invited Talks
- *2023.05*, CAU-AI ÌïµÏã¨ Í∏∞Ïà†ÏÑ∏ÎØ∏ÎÇò, Empirical Methods and Recent Topics for Video Moment Retrieval, (2023-05-19) 

# üìù Publications 

[*] equal contribution

## 2023

<div class='paper-box'><div class='paper-box-image'><div class="badge">EMNLP 2023</div><img src='images/emnlp2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

HEAR: Hearing Enhanced Audio Response for Viode-grounded Dialogue

**Sunjae Yoon**, Dahyun Kim, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, Chang D. Yoo

Empirical Methods in Natural Language Processing (**EMNLP**) 2023 (long paper, findings)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICCV 2023</div><img src='images/iccv2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[SCANet: Scene Complexity Aware Network for Weakly-supervised Video Moment Retrieval](https://openaccess.thecvf.com/content/ICCV2023/papers/Yoon_SCANet_Scene_Complexity_Aware_Network_for_Weakly-Supervised_Video_Moment_Retrieval_ICCV_2023_paper.pdf)

**Sunjae Yoon**, Gwanhyeong Koo, Dahyun Kim, Chang D. Yoo

International Conference on Computer Vision (**ICCV**) 2023

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2023</div><img src='images/icassp2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Counterfactual Two-stage Debiasing Network for Video Corpus Moment Retrieval](https://ieeexplore.ieee.org/document/10095182)

**Sunjae Yoon**, Ji Woo Hong, SooHwan Eom, Hee Suk Yoon, Eunseop Yoon, Daehyeok Kim, Junyeong Kim, Chanwoo Kim, Chang D. Yoo

The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2023, **Oral**

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2023</div><img src='images/access2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Joint Path Alignment Framework for 3D Human Pose and Shape Estimation from Video](https://ieeexplore.ieee.org/document/10109716)

Ji Woo Hong, **Sunjae Yoon**, Junyeong Kim, Chang D. Yoo  

IEEE Access, 2023

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICLR 2023</div><img src='images/iclr2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[ESD: EXPECTED SQUARED DIFFERENCE AS A TUNING-FREE TRAINABLE CALIBRATION MEASURE](https://arxiv.org/pdf/2303.02472.pdf)

Hee Suk Yoon, Joshua Tian Jin Tee , Eunseop Yoon, **Sunjae Yoon**, Gwangsu Kim, Yingzhen Li, Chang D. Yoo 

International Conference on Learning Representation (**ICLR**), 2023

</div>
</div>

## 2022

<div class='paper-box'><div class='paper-box-image'><div class="badge">EMNLP 2022</div><img src='images/emnlp2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue](https://browse.arxiv.org/pdf/2212.05765.pdf)

**Sunjae Yoon**, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, Chang D. Yoo

Empirical Methods in Natural Language Processing (**EMNLP**), 2022. (long paper)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">EMNLP 2022</div><img src='images/emnlp2022_findings.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[SMSMix: Sense-Maintained Sentence Mixup for Word Sense Disambiguation](https://arxiv.org/pdf/2212.07072.pdf)

Hee Suk Yoon , Eunseop Yoon , John Harvill, **Sunjae Yoon**, Mark Hasegawa-Johnson, and Chang D. Yoo

Empirical Methods in Natural Language Processing (**EMNLP**), 2022. (long paper)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2022</div><img src='images/eccv2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Selective Query-guided Debiasing for Video Corpus Moment Retrieval](https://arxiv.org/pdf/2210.08714.pdf) 

[[code]](https://github.com/dbstjswo505/SQuiDNet)

**Sunjae Yoon**, Ji Woo Hong, Eunseop Yoon, Dahyun Kim , Junyeong Kim, Hee Suk Yoon, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2022

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2022</div><img src='images/access2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Cascaded MPN: Cascaded Moment Proposal Network for Video Corpus Moment Retrieval](https://ieeexplore.ieee.org/document/9795270) 

**Sunjae Yoon**, Dahyun Kim, Junyeong Kim, and Chang D. Yoo

IEEE Access 2022

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2022</div><img src='images/icassp2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[SEMANTIC ASSOCIATION NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL](https://ieeexplore.ieee.org/document/9747523) 

Dahyun Kim *, **Sunjae Yoon** *, Ji Woo Hong, and Chang D. Yoo

The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2022. **Oral**

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Sensors 2022</div><img src='images/sensors2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Dual-Scale Doppler Attention for Human Identification](https://www.mdpi.com/1424-8220/22/17/6363) 

[[code]](https://github.com/dbstjswo505/DSDA)

**Sunjae Yoon**, Dahyun Kim, Ji Woo Hong, and Chang D. Yoo

MDPI Sensors, 2022

</div>
</div>

## 2021

<div class='paper-box'><div class='paper-box-image'><div class="badge">AAAI 2022</div><img src='images/aaai2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Structured Co-reference Graph Attention for Video-grounded Dialogue](https://arxiv.org/pdf/2103.13361.pdf) 

Junyeong Kim, **Sunjae Yoon**, Dahyun Kim, and Chang D. Yoo

AAAI Association for the Advancement of Artificial Intelligence (**AAAI**), 2021

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICIP 2021</div><img src='images/icip2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[WEAKLY-SUPERVISED MOMENT RETRIEVAL NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL](https://ieeexplore.ieee.org/document/9506218) 

[[code]](https://github.com/dbstjswo505/WMRN)

**Sunjae Yoon** *, Dahyun Kim *, Ji Woo Hong, Junyeong Kim, Kookhoi Kim and Chang D. Yoo

International Conference on Image Processing (**ICIP**), 2021

</div>
</div>

## 2020

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2020</div><img src='images/eccv2020.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval**](https://arxiv.org/pdf/2008.10238.pdf)

Minuk Ma *, **Sunjae Yoon** *, Junyeong Kim, Youngjuoon Lee, Sunghun Kang, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2020

</div>
</div>


# üéñ Honors and Awards
- *2021.10* JKAIA 2023. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 


# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.