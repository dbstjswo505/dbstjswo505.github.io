---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# üòÉ About me

I graduated from the Daegu Gyeongbuk Institute of Science & Technology (DGIST) with a B.S. in Computer Engineering in 2019 and from Korea Advanced Institute of Science& Technology (KAIST) with a M.S. in Electric Engineering in 2021. I decided to continue my education and pursue a Ph.D. in the field of Artificial Intelligence/Deep Learning. I am currently working under the guidance of Professor [Chang D. Yoo](http://sanctusfactory.com/family.php), whose expertise and leadership have been invaluable to my research.

My research focuses on the reliability of Artificial Intelligence/Deep Learning technologies for various modalities, including images, videos, and natural language. I am passionate about exploring the potential of these technologies and finding ways to improve their performance and reliability in real-world applications. Here is [CV](https://drive.google.com/file/d/1kDQDw_m0SH67cUGQzCE2LJHY1CCOoS0q/view?usp=sharing) for more information about me.

# üìå Research Interests
- Computer Vision
- Natural Language Processing
- Multi-modal Reasoning
- Causality and Debiasing
- Generative AI


# üî• News
- *2024.01*: &nbsp;üéâ One paper accepted to IEEE Access 2024
- *2023.12*: &nbsp;üéâ One paper accepted to ICASSP 2024 
- *2023.12*: &nbsp;üéâ One paper accepted to AAAI 2024 
- *2023.11*: &nbsp;üèÜ I got [Best Paper Award](https://ee.kaist.ac.kr/en/research-achieve/ph-d-candidate-sunjae-yoon-prof-chang-d-yoo-wins-best-paper-award/) in JKAIA 2023 

# üè´ Education

- Mar.2021 - Current: __Ph.D candidate__ Electrical Engineering (KAIST)

&emsp;&emsp;&emsp;Advisor: Prof. Chang D. Yoo

- Sep.2019 - Feb.2021: __M.S.__ Electrical Engineering (KAIST)

&emsp;&emsp;&emsp;Thesis: "Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval"

&emsp;&emsp;&emsp;Advisor: Prof. Chang D. Yoo

- Mar.2015 - Feb.2019: __B.S.__ Computer Engineering (DGIST)

# üìé Selected Publications 

[**1**] **Sunjae Yoon**, Dahyun Kim, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, and Chang D. Yoo, "HEAR: Hearing Enhanced Audio Response for Viode-grounded Dialogue", Empirical Methods in Natural Language Processing (**EMNLP**) 2023 (long paper, findings)

[**2**] **Sunjae Yoon**, Gwanhyeong Koo, Dahyun Kim, and Chang D. Yoo "SCANet: Scene Complexity Aware Network for Weakly-supervised Video Moment Retrieval", International Conference on Computer Vision (**ICCV**) 2023

[**3**] **Sunjae Yoon**, Ji Woo Hong, SooHwan Eom, Hee Suk Yoon, Eunseop Yoon, Daehyeok Kim, Junyeong Kim, Chanwoo Kim, and Chang D. Yoo, "Counterfactual Two-stage Debiasing Network for Video Corpus Moment Retrieval", The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2023, **Oral**

[**4**] **Sunjae Yoon**, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, and Chang D. Yoo "Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue", Empirical Methods in Natural Language Processing (**EMNLP**), 2022. (long paper)

[**5**] **Sunjae Yoon**, Ji Woo Hong, Eunseop Yoon, Dahyun Kim , Junyeong Kim, Hee Suk Yoon, and Chang D. Yoo, "Selective Query-guided Debiasing for Video Corpus Moment Retrieval", European Conference on Computer Vision (**ECCV**) 2022

[**6**] Minuk Ma *, **Sunjae Yoon** *, Junyeong Kim, Youngjuoon Lee, Sunghun Kang, and Chang D. Yoo, "VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval", European Conference on Computer Vision (**ECCV**) 2020 (equal contribution)

# üìù Publications 

[*] equal contribution

## 2024

<div class='paper-box'><div class='paper-box-image'><div class="badge">IEEE Access 2024</div><img src='images/access2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J4**] Causal Localization Network for Radar Human Localization with micro-Doppler signature

**Sunjae Yoon**, Gwanhyeong Koo, Jun Yeop Shim, Soohwan Eom, Ji Woo Hong, Chang D. Yoo

IEEE Access, 2023
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2024</div><img src='images/icassp2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C13**] WAVELET-GUIDED ACCELERATION OF TEXT INVERSION IN DIFFUSION-BASED IMAGE EDITING

Gwanhyeong Koo, **Sunjae Yoon**, Chang D. Yoo

The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2024
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">AAAI 2024</div><img src='images/aaai2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C12**] [**SimPSI: A Simple Strategy to Preserve Spectral Information in Time Series Data Augmentation**](https://arxiv.org/pdf/2312.05790.pdf)

Hyun Ryu, **Sunjae Yoon**, Hee Suk Yoon, Eunseop Yoon, and Chang D. Yoo

AAAI Association for the Advancement of Artificial Intelligence (**AAAI**) 2024

[[code]](https://github.com/Hyun-Ryu/simpsi)
</div>
</div>

## 2023

<div class='paper-box'><div class='paper-box-image'><div class="badge">EMNLP 2023</div><img src='images/hear.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C11**] [**HEAR: Hearing Enhanced Audio Response for Viode-grounded Dialogue**](https://aclanthology.org/2023.findings-emnlp.797.pdf)

**Sunjae Yoon**, Dahyun Kim, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, and Chang D. Yoo

Empirical Methods in Natural Language Processing (**EMNLP**) 2023 (long paper, findings)

[[code]](https://github.com/dbstjswo505/HEAR)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICCV 2023</div><img src='images/iccv2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C10**] [**SCANet: Scene Complexity Aware Network for Weakly-supervised Video Moment Retrieval**](https://openaccess.thecvf.com/content/ICCV2023/papers/Yoon_SCANet_Scene_Complexity_Aware_Network_for_Weakly-Supervised_Video_Moment_Retrieval_ICCV_2023_paper.pdf)

**Sunjae Yoon**, Gwanhyeong Koo, Dahyun Kim, and Chang D. Yoo

International Conference on Computer Vision (**ICCV**) 2023

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2023</div><img src='images/icassp2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C9**] [**Counterfactual Two-stage Debiasing Network for Video Corpus Moment Retrieval**](https://ieeexplore.ieee.org/document/10095182)

**Sunjae Yoon**, Ji Woo Hong, SooHwan Eom, Hee Suk Yoon, Eunseop Yoon, Daehyeok Kim, Junyeong Kim, Chanwoo Kim, and Chang D. Yoo

The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2023, **Oral**

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2023</div><img src='images/access2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J3**] [**Joint Path Alignment Framework for 3D Human Pose and Shape Estimation from Video**](https://ieeexplore.ieee.org/document/10109716)

Ji Woo Hong, **Sunjae Yoon**, Junyeong Kim, and Chang D. Yoo  

IEEE Access, 2023

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICLR 2023</div><img src='images/iclr2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C8**] [**ESD: EXPECTED SQUARED DIFFERENCE AS A TUNING-FREE TRAINABLE CALIBRATION MEASURE**](https://arxiv.org/pdf/2303.02472.pdf)

Hee Suk Yoon, Joshua Tian Jin Tee , Eunseop Yoon, **Sunjae Yoon**, Gwangsu Kim, Yingzhen Li, and Chang D. Yoo 

International Conference on Learning Representation (**ICLR**), 2023

</div>
</div>

## 2022

<div class='paper-box'><div class='paper-box-image'><div class="badge">EMNLP 2022</div><img src='images/emnlp2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C7**] [**Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue**](https://browse.arxiv.org/pdf/2212.05765.pdf)

**Sunjae Yoon**, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, and Chang D. Yoo

Empirical Methods in Natural Language Processing (**EMNLP**), 2022. (long paper)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">EMNLP 2022</div><img src='images/emnlp2022_findings.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C6**] [**SMSMix: Sense-Maintained Sentence Mixup for Word Sense Disambiguation**](https://arxiv.org/pdf/2212.07072.pdf)

Hee Suk Yoon , Eunseop Yoon , John Harvill, **Sunjae Yoon**, Mark Hasegawa-Johnson, and Chang D. Yoo

Empirical Methods in Natural Language Processing (**EMNLP**), 2022. (short paper, findings)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2022</div><img src='images/eccv2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C5**] [**Selective Query-guided Debiasing for Video Corpus Moment Retrieval**](https://arxiv.org/pdf/2210.08714.pdf) 

[[code]](https://github.com/dbstjswo505/SQuiDNet)

**Sunjae Yoon**, Ji Woo Hong, Eunseop Yoon, Dahyun Kim , Junyeong Kim, Hee Suk Yoon, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2022

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2022</div><img src='images/access2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J2**] [**Cascaded MPN: Cascaded Moment Proposal Network for Video Corpus Moment Retrieval**](https://ieeexplore.ieee.org/document/9795270) 

**Sunjae Yoon**, Dahyun Kim, Junyeong Kim, and Chang D. Yoo

IEEE Access 2022

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2022</div><img src='images/icassp2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C4**] [**SEMANTIC ASSOCIATION NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL**](https://ieeexplore.ieee.org/document/9747523) 

Dahyun Kim *, **Sunjae Yoon** *, Ji Woo Hong, and Chang D. Yoo

The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2022. **Oral**

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Sensors 2022</div><img src='images/sensors2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J1**] [**Dual-Scale Doppler Attention for Human Identification**](https://www.mdpi.com/1424-8220/22/17/6363) 

[[code]](https://github.com/dbstjswo505/DSDA)

**Sunjae Yoon**, Dahyun Kim, Ji Woo Hong, and Chang D. Yoo

MDPI Sensors, 2022

</div>
</div>

## 2021

<div class='paper-box'><div class='paper-box-image'><div class="badge">AAAI 2021</div><img src='images/aaai2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C3**] [**Structured Co-reference Graph Attention for Video-grounded Dialogue**](https://arxiv.org/pdf/2103.13361.pdf) 

Junyeong Kim, **Sunjae Yoon**, Dahyun Kim, and Chang D. Yoo

AAAI Association for the Advancement of Artificial Intelligence (**AAAI**), 2021

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICIP 2021</div><img src='images/icip2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C2**] [**WEAKLY-SUPERVISED MOMENT RETRIEVAL NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL**](https://ieeexplore.ieee.org/document/9506218) 

[[code]](https://github.com/dbstjswo505/WMRN)

**Sunjae Yoon** *, Dahyun Kim *, Ji Woo Hong, Junyeong Kim, Kookhoi Kim and Chang D. Yoo

International Conference on Image Processing (**ICIP**), 2021

</div>
</div>

## 2020

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2020</div><img src='images/eccv2020.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C1**] [**VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval**](https://arxiv.org/pdf/2008.10238.pdf)

Minuk Ma *, **Sunjae Yoon** *, Junyeong Kim, Youngjuoon Lee, Sunghun Kang, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2020

</div>
</div>

# Academic Activities

# üí¨ Invited Talks
- *2023.05*, CAU-AI ÌïµÏã¨ Í∏∞Ïà†ÏÑ∏ÎØ∏ÎÇò, Empirical Methods and Recent Topics for Video Moment Retrieval, (2023-05-19) 

# üèÜ Awards

- Best Paper Award, Winter Conference, JKAIA, (2023.11)

- ‚ÄòGovernor citation‚Äô from the governor of DAEGU CITY DALSEONG GUN (2019.02)

- Award Bronze Prize for International University Creative Car Competition (Autonomous driving) by Korea Transportation Safety Authority, (2018.05)

- Award Excellence Prize in Autonomous Vehicle Creation Technology by Korea Auto Vehicle Safety Association, (2018.05)

# üìë Reviewer

**Confernce**

- Neural Information Processing Systems (**Neurips**): 2023

- IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**) : 2022, 2023, 2024

- European Conference on Computer Vision (**ECCV**): 2022

- IEEE International Conference on Computer Vision (**ICCV**) : 2023

- Association for Computational Linguistics (**ACL**): 2023

- Empirical Methods on Natural Language Processing (**EMNLP**): 2022, 2023

- International Conference on Learning Representations (**ICLR**): 2024

- International Conference on Machine Learning (**ICML**): 2024

- International Conference on Acoustics, Speech, and Signal Processing (**ICASSP**): 2023, 2024

- IEEE/CVF Winter Conference on Applications of Computer Vision (**WACV**): 2023, 2024

**Journal**
- IEEE Transactions on Big Data

# üéè Patent

- Selective Query-guided Debiasing for Video Corpus Moment Retrieval No. KR 10-2022-0154621 (2022-11-17)

- WEAKLY-SUPERVISED MOMENT RETRIEVAL NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL No. KR 10-2021-0172582 (2021-12-06)

- Artificial Intelligence-based Radar Target Detection System No. KR 10-2021-0013581 (2021-01-29)